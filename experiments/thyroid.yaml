configuration:
  batch_size: 16
  optimizer: torch.optim.AdamW

  lr: 0.0001
  trainer: experiment_setup.train_loop
  scorer: experiment_setup.score
  model: models.cliptn.CLIPTNseg

  lr_scheduler: cosine
  T_max: 30000
  eta_min: 0.000001

  max_iterations: 30000
  val_interval: 500

  # dataset
  dataset: datasets.thyroid.PhraseCut   # <-----------------
  split_mode: pascal_test
  split: train
  mask: text_and_crop_blur_highlight352
  image_size: 352
  normalize: True
  pre_crop_image_size: [sample, 1, 1.5]
  aug: 1new
  aug_rotate: False


  # general
  mix: True # <-----------------
  prompt: plain
  norm_cond: True
  mix_text_min: 0.0
  
  # model5
  out: 1
  extract_layers: [3,7,9]
  reduce_dim: 64
  depth: 3
  fix_shift: False

  loss: torch.nn.functional.binary_cross_entropy_with_logits
  amp: True

test_configuration_common:
  normalize: True
  image_size: 352
  batch_size: 32
  # max_iterations: 5
  # max_iterations: 150
  
test_configuration: 

  -
    name: tn1005  # old: phrasecut
    metric: metrics.FixedIntervalMetrics
    test_dataset: phrasecut
    split: test
    mask: text
    label_support: True
    sigmoid: True



individual_configurations:

- {name: rd64-uni, version: 'ViT-B/16', reduce_dim: 64, with_visual: True, negative_prob: 0, mix: True, mix_text_max: 1}


